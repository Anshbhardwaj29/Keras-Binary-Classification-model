# -*- coding: utf-8 -*-
"""keras Binary classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18ILnwhsC_WigoTX2_rkfoUa93PwJrULB
"""

from sklearn.datasets import make_moons

x, y = make_moons(noise = .1, random_state=0)

import pandas as pd
df = pd.DataFrame(x)
df['y'] = y

df.head()

df0  = df[df['y']==0]
df1 = df[df['y']==1]

df0.head()

df1.head()

import matplotlib.pyplot as plt
plt.scatter(df0[0], df0[1])
plt.scatter(df1[0], df1[1])
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = .33, random_state = 42)

X_train.shape

X_test.shape

import tensorflow as tf
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(8, input_shape = X_train[0].shape, activation = 'relu'))
model.add(tf.keras.layers.Dense(4, activation = 'relu'))
model.add(tf.keras.layers.Dense(2, activation = 'relu'))
model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))

model.summary()

model.compile(loss = tf.keras.losses.BinaryCrossentropy(),optimizer = 'adam', metrics=['accuracy'])

callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 3)
history = model.fit(X_train, Y_train, epochs=1000, validation_data = (X_test, Y_test), callbacks = [callback])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.xlabel('loss')
plt.ylabel('val_loss')
plt.legend()
plt.show()

from mlxtend.plotting import plot_decision_regions
plot_decision_regions(X_test, Y_test, clf = model)

